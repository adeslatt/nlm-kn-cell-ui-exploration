{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18739291",
   "metadata": {},
   "source": [
    "# NLM UI Exploration using scverse Pseudo-bulk functional analysis with NSForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438be8ce",
   "metadata": {},
   "source": [
    "Using a dataset from the `COvid-19 Multi-omics Blood ATlas (COMBAT) Consortium` published in 2022 in Cell `A blood atlas of COVID-19 defines hallmarks of disease severity and specificity`.  We will explore possible user interfaces to answer questions about cell types.\n",
    "\n",
    "When cell lineage is clear (there are clear cell identity clusters), it might be beneficial to perform functional analyses at the pseudo-bulk level instead of the single-cell.\n",
    "By doing so, we recover lowly expressed genes that before where affected by the \"drop-out\" effect of single-cell. \n",
    "Additionaly, if there is more than one condition in our data, we can perform differential expression analysis (DEA) and use the gene statistics as input for enrichment analysis.\n",
    "\n",
    "In this notebook we showcase how to use `decoupler` for pathway and transcription factor (TF) enrichment from a human data-set. The data consists of ~5k Blood myeloid cells from healthy and COVID-19 infected patients available in the Single Cell Expression Atlas [here](https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-9221/results?plotType=umap&plotOption=20).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "    \n",
    "This notebook assumes that you already know the basics of `decoupler`. Else, check out the [Usage](https://decoupler-py.readthedocs.io/en/latest/notebooks/usage.html) tutorial first.   A version is in `adeslatt` github to allow it to run on MacOS.\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4bc71",
   "metadata": {},
   "source": [
    "## for local execution on a MacOS - modifications by adeslatt*\n",
    "\n",
    "To pull from the cellxgene the appropriate data set, additional packages need to be installed:\n",
    "\n",
    "```bash\n",
    "pip install cellxgene-census scanpy scvi-tools\n",
    "```\n",
    "\n",
    "The rest of these also need to be preformed.\n",
    "\n",
    "* create a clean conda env\n",
    "* install in this environment the required packages that are in the *import* line\n",
    "* install done 2024-10-20 - needed to restrict python version\n",
    "* decoupler not available in bioconda at the right version and not present in conda-forge\n",
    "* pip install decoupler instead\n",
    "\n",
    "In a bash shell.  If you are already in an environment, be sure to deactivate it to get to your base environment.\n",
    "\n",
    "install jupyter and kernels of interest\n",
    "\n",
    "installing scanpy installs numpy \n",
    "\n",
    "```bash\n",
    "conda update -n base -c defaults conda\n",
    "conda create -n scverse python=3.12.7\n",
    "conda activate scverse\n",
    "conda install conda-forge::jupyter -y\n",
    "conda install conda-forge::ipykernel -y\n",
    "conda install conda-forge::r-irkernel -y\n",
    "conda install conda-forge::bash_kernel -y\n",
    "conda install conda-forge::scanpy -y\n",
    "pip install decoupler\n",
    "```\n",
    "\n",
    "## first run resulted in an error\n",
    "\n",
    "Return to the bash shell within your conda environment and upgrade the decoupler package.\n",
    "Other missing packages:\n",
    "1. pybiomart - the python front end for biomart\n",
    "2. marsilea\n",
    "3. pydeseq2 - the python front end to DESeq2\n",
    "4. igraph\n",
    "5. adjustText\n",
    "6. pypath-omnipath\n",
    "\n",
    "\n",
    "```bash\n",
    " pip install pybiomart\n",
    " pip install marsilea\n",
    " pip install pydeseq2\n",
    " pip install igraph\n",
    " pip install adjustText\n",
    " pip install omnipath\n",
    "```\n",
    "\n",
    "The above fixes the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50601323-f124-46cd-8427-77a400a21788",
   "metadata": {},
   "source": [
    "## Using the CELLxGENE Census API to pull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e6450-2471-4a05-b199-c48a5f1c7e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 836148 cells for dataset: ebc2e1ff-c8f9-466a-acf4-9d291afaf8b3\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import cellxgene_census\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "def load_and_prepare_cellxgene_data(dataset_id: str, columns: list, new_column_names: list):\n",
    "    \"\"\"\n",
    "    Pull scRNA-seq data from CELLxGENE Census, filter for the specified metadata columns, and rename them.\n",
    "    \n",
    "    Args:\n",
    "    - dataset_id (str): The specific dataset_id to filter (e.g., \"ebc2e1ff-c8f9-466a-acf4-9d291afaf8b3\").\n",
    "    - columns (list): List of columns to keep from the original metadata.\n",
    "    - new_column_names (list): List of new column names for renaming the metadata.\n",
    "    \n",
    "    Returns:\n",
    "    - AnnData object with specified columns and renamed metadata.\n",
    "    \"\"\"\n",
    "    # Use the stable census version\n",
    "    stable_version = \"2024-07-01\"  # You can adjust to another stable version if needed\n",
    "    \n",
    "    with cellxgene_census.open_soma(census_version=stable_version) as census:\n",
    "        # Correct API call to fetch observation metadata\n",
    "        obs_df = cellxgene_census.get_obs(\n",
    "            census=census,\n",
    "            organism=\"homo_sapiens\",\n",
    "            value_filter=f\"dataset_id == '{dataset_id}'\"\n",
    "        )\n",
    "\n",
    "        if obs_df.empty:\n",
    "            raise ValueError(f\"No cells found for dataset with ID: {dataset_id}\")\n",
    "        \n",
    "        print(f\"Found {obs_df.shape[0]} cells for dataset: {dataset_id}\")\n",
    "\n",
    "        # 2. Get the list of soma_joinid (cell indices) to use in coords\n",
    "        cell_indices = obs_df[\"soma_joinid\"].tolist()\n",
    "\n",
    "        # 3. Retrieve the RNA expression data for the filtered cells\n",
    "        raw_counts_data = census[\"census_data\"][\"homo_sapiens\"].ms[\"RNA\"].X[\"raw\"]\n",
    "\n",
    "        # Use coords to filter by the specific cell indices\n",
    "        expr_data_iter = raw_counts_data.read(coords=(cell_indices,)).tables()\n",
    "\n",
    "        # 4. Collect the data into lists for COO matrix construction\n",
    "        coo_data = []\n",
    "        coo_row = []\n",
    "        coo_col = []\n",
    "\n",
    "        for batch in expr_data_iter:\n",
    "            # Collect the batch's non-zero values and coordinates\n",
    "            coo_data.extend(batch[\"soma_data\"].to_numpy())\n",
    "            coo_row.extend(batch[\"soma_dim_0\"].to_numpy())  # Cell indices (row)\n",
    "            coo_col.extend(batch[\"soma_dim_1\"].to_numpy())  # Gene indices (column)\n",
    "\n",
    "        # 5. Create a COO sparse matrix using the collected data\n",
    "        coo_matrix = sparse.coo_matrix((coo_data, (coo_row, coo_col)))\n",
    "\n",
    "        # 6. Convert COO to CSR format (AnnData requires this)\n",
    "        expr_sparse_matrix = coo_matrix.tocsr()\n",
    "\n",
    "        # 7. Construct an AnnData object using the filtered obs and the count matrix\n",
    "        adata = sc.AnnData(X=expr_sparse_matrix, obs=obs_df)\n",
    "\n",
    "        # 8. Filter and rename columns in obs\n",
    "        adata.obs = adata.obs[columns]\n",
    "        adata.obs.columns = new_column_names\n",
    "\n",
    "        # Optional: store raw counts in a dedicated layer\n",
    "        adata.layers[\"counts\"] = adata.X\n",
    "\n",
    "        return adata\n",
    "\n",
    "# Define the columns of interest and their new names\n",
    "columns = ['sex', 'donor_id', 'disease', 'cell_type']\n",
    "new_column_names = ['sex', 'individual', 'disease', 'cell_type']\n",
    "\n",
    "# Example usage: Loading the COMBAT dataset and renaming metadata columns\n",
    "adata = load_and_prepare_cellxgene_data(\"ebc2e1ff-c8f9-466a-acf4-9d291afaf8b3\", columns, new_column_names)\n",
    "\n",
    "# Now adata is ready for further analysis\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f309e-6f73-45bc-a626-51ba65dcc36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d226515c-1368-41e1-ad57-6a2a746f9758",
   "metadata": {},
   "source": [
    "## Loading additional packages\n",
    "\n",
    "First, we need to load the relevant packages, `scanpy` to handle scRNA-seq data\n",
    "and `decoupler` to use statistical methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90250f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import decoupler as dc\n",
    "\n",
    "# Only needed for processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# needed for writing h5ad objects\n",
    "import json\n",
    "\n",
    "# Needed for some plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting options, change to your liking\n",
    "sc.settings.set_figure_params(dpi=200, frameon=False)\n",
    "sc.set_figure_params(dpi=200)\n",
    "sc.set_figure_params(figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c04508",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We can download the data easily using `scanpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data-set \n",
    "adata = sc.datasets.ebi_expression_atlas(\"E-MTAB-9221\", filter_boring=True)\n",
    "\n",
    "# Rename meta-data\n",
    "columns = ['Sample Characteristic[sex]',\n",
    "           'Sample Characteristic[individual]',\n",
    "           'Sample Characteristic[disease]',\n",
    "           'Factor Value[inferred cell type - ontology labels]']\n",
    "adata.obs = adata.obs[columns]\n",
    "adata.obs.columns = ['sex','individual','disease','cell_type']\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1645cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing\n",
    "\n",
    "This specific data-set contains ensmbl gene ids instead of gene symbols. \n",
    "To be able to use `decoupler` we need to transform them into gene symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84729a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve gene symbols\n",
    "annot = sc.queries.biomart_annotations(\"hsapiens\",\n",
    "        [\"ensembl_gene_id\", \"external_gene_name\"],\n",
    "        use_cache=False\n",
    "    ).set_index(\"ensembl_gene_id\")\n",
    "\n",
    "# Filter genes not in annotation\n",
    "adata = adata[:, adata.var.index.intersection(annot.index)]\n",
    "\n",
    "# Assign gene symbols\n",
    "adata.var['gene_symbol'] = [annot.loc[ensembl_id,'external_gene_name'] for ensembl_id in adata.var.index]\n",
    "adata.var = adata.var.reset_index().rename(columns={'index': 'ensembl_gene_id'}).set_index('gene_symbol')\n",
    "\n",
    "# Remove genes with no gene symbol\n",
    "adata = adata[:, ~pd.isnull(adata.var.index)]\n",
    "\n",
    "# Remove duplicates\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63816f60",
   "metadata": {},
   "source": [
    "Since the meta-data of this data-set is available, we can filter cells that were not annotated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa28500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-annotated cells\n",
    "adata = adata[~adata.obs['cell_type'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2dc7",
   "metadata": {},
   "source": [
    "We will store the raw counts in the `.layers` attribute so that we can use them\n",
    "afterwards to generate pseudo-bulk profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw counts in layers\n",
    "adata.X = np.round(adata.X)\n",
    "adata.layers['counts'] = adata.X\n",
    "\n",
    "# Normalize and log-transform\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.layers['normalized'] = adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48e0cc",
   "metadata": {},
   "source": [
    "We can also look how cells cluster by cell identity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, batch_key='individual')\n",
    "\n",
    "# Scale the data\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "# Generate PCA features\n",
    "sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True)\n",
    "\n",
    "# Compute distances in the PCA space, and find cell neighbors\n",
    "sc.pp.neighbors(adata)\n",
    "\n",
    "# Generate UMAP features\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "# Visualize\n",
    "sc.pl.umap(adata, color=['disease','cell_type'], frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f765ae1",
   "metadata": {},
   "source": [
    "In this data-set we have two condition, `COVID-19` and `healthy`, across 6 different cell types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d794c94",
   "metadata": {},
   "source": [
    "## Generation of pseudo-bulk profiles\n",
    "\n",
    "After the annotation of clusters into cell identities, we often would like to perform differential expression analysis (DEA) between conditions within particular cell types to further characterize them. DEA can be performed at the single-cell level, but the obtained p-values are often inflated as each cell is treated as a sample. We know that single cells within a sample are not independent of each other, since they were isolated from the same environment. If we treat cells as samples, we are not testing the variation across a population of samples, rather the variation inside an individual one. Moreover, if a sample has more cells than another it might bias the results. \n",
    "\n",
    "The current best practice to correct for this is using a pseudo-bulk approach ([Squair J.W., et al 2021](https://doi.org/10.1038/s41467-021-25960-2)), which involves the following steps:\n",
    "\n",
    "1. Subsetting the cell type(s) of interest to perform DEA.\n",
    "2. Extracting their raw integer counts.\n",
    "3. Summing their counts per gene into a single profile if they pass quality control.\n",
    "4. Performing DEA if at least two biological replicates per condition are available (more replicates are recommended).\n",
    "\n",
    "We can pseudobulk using the function `decoupler.get_pseudobulk`. In this example, we are interested in summing the counts but other\n",
    "modes are available, for more information check its argument `mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pseudo-bulk profile\n",
    "pdata = dc.get_pseudobulk(\n",
    "    adata,\n",
    "    sample_col='individual',\n",
    "    groups_col='cell_type',\n",
    "    layer='counts',\n",
    "    mode='sum',\n",
    "    min_cells=0,\n",
    "    min_counts=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a421ee-3cf2-4dc9-8f4b-7c4b2a38e3a1",
   "metadata": {},
   "source": [
    "It has generated a profile for each sample and cell type. We can plot their quality control metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16492c1f-a2ec-45ef-9a94-63f7acdd0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_psbulk_samples(pdata, groupby=['individual', 'cell_type'], figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31d66a-7a93-4033-8dae-3e664bea05ba",
   "metadata": {},
   "source": [
    "There are two criteria to filter low quality samples: its number of cells (`psbulk_n_cells`), and its total sum of counts (`psbulk_counts`).\n",
    "In these plots it can be seen that there are some samples of platelet cells that contain less than 10 cells, we might want to remove\n",
    "them by using the arguments `min_cells` and `min_counts`. Note that these thresholds are arbitrary and will change depening on the\n",
    "dataset, but a good rule of thumb is to have at least 10 cells with 1000 accumulated counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7dbd88-4648-4ad9-83c4-39e76f1c7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filtered pseudo-bulk profile\n",
    "pdata = dc.get_pseudobulk(\n",
    "    adata,\n",
    "    sample_col='individual',\n",
    "    groups_col='cell_type',\n",
    "    layer='counts',\n",
    "    mode='sum',\n",
    "    min_cells=10,\n",
    "    min_counts=1000\n",
    ")\n",
    "pdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40297690",
   "metadata": {},
   "source": [
    "### Exploration of pseudobulk profiles\n",
    "Now that we have generated the pseudobulk profiles for each patient and each cell type, let's explore the variability between them. For that, we will first do some simple preprocessing and then do a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw counts in layers\n",
    "pdata.layers['counts'] = pdata.X.copy()\n",
    "\n",
    "# Normalize, scale and compute pca\n",
    "sc.pp.normalize_total(pdata, target_sum=1e4)\n",
    "sc.pp.log1p(pdata)\n",
    "sc.pp.scale(pdata, max_value=10)\n",
    "sc.tl.pca(pdata)\n",
    "\n",
    "# Return raw counts to X\n",
    "dc.swap_layer(pdata, 'counts', X_layer_key=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(pdata, color=['disease', 'cell_type'], ncols=1, size=300)\n",
    "sc.pl.pca_variance_ratio(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e3618",
   "metadata": {},
   "source": [
    "When looking at the PCA, it seems like the two first components explain most of the variance and they easily separate cell types from one another. In contrast, the principle components do not seem to be associated with disease status as such.\n",
    "\n",
    "In order to have a better overview of the association of PCs with sample metadata, let's perform ANOVA on each PC and see whether they are significantly associated with any technical or biological annotations of our samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1ae46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dc.get_metadata_associations(\n",
    "    pdata,\n",
    "    obs_keys = ['sex', 'disease', 'cell_type', 'psbulk_n_cells', 'psbulk_counts'],  # Metadata columns to associate to PCs\n",
    "    obsm_key='X_pca',  # Where the PCs are stored\n",
    "    uns_key='pca_anova',  # Where the results are stored\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5e25d-d7e2-4275-b2d8-afd704a00135",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_associations(\n",
    "    pdata,\n",
    "    uns_key='pca_anova',  # Summary statistics from the anova tests\n",
    "    obsm_key='X_pca',  # where the PCs are stored\n",
    "    stat_col='p_adj',  # Which summary statistic to plot\n",
    "    obs_annotation_cols = ['disease', 'cell_type'], # which sample annotations to plot\n",
    "    titles=['Principle component scores', 'Adjusted p-values from ANOVA'],\n",
    "    figsize=(7, 5),\n",
    "    n_factors=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf93a2",
   "metadata": {},
   "source": [
    "On the PCA plots above, T and B cells seemed not to be that well separated. However when looking at the hierarchical clustering in the heatmap, one can see that the inclusion of more PCs helps to distinguish them.\n",
    "\n",
    "When looking at the p-values from the ANOVA models, it becomes clear that the top PCs, which explain most of the observed variability, are statistically associated with the `cell_type` category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20818444-b8a3-45f4-b868-5a201c74a71a",
   "metadata": {},
   "source": [
    "### Pseudo-bulk profile gene filtering\n",
    "Additionally to filtering low quality samples, we can also filter noisy expressed genes in case we want to perform downstream analyses such as DEA afterwards. Note that this step should be done at the cell type level, since each cell type may express different collection of genes.\n",
    "\n",
    "For this vignette, we will explore the effects of COVID on T cells. Let's first select our samples of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe51328-e326-4c35-8c93-edc24220f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select T cell profiles\n",
    "tcells = pdata[pdata.obs['cell_type'] == 'T cell'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd4386-9c7c-4fe5-90d2-4f905c8e2bc5",
   "metadata": {},
   "source": [
    "To filter genes, we will follow the strategy implemented in the function `filterByExpr` from [edgeR](https://rdrr.io/bioc/edgeR/man/filterByExpr.html).\n",
    "It keeps genes that have a minimum total number of reads across samples (`min_total_count`), and that have a minimum number of counts in a number of samples (`min_count`).\n",
    "\n",
    "We can plot how many genes do we keep, you can play with the `min_count` and `min_total_count` to check how many genes would be kept when changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a73fc-2b21-4042-9574-5846328a1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_filter_by_expr(tcells, group='disease', min_count=10, min_total_count=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d139f-401f-4704-92bf-5699b5b4d135",
   "metadata": {},
   "source": [
    "Here we can observe the frequency of genes with different total sum of counts and number of samples. The dashed lines indicate the current thresholds, meaning that only the genes in the upper-right corner are going to be kept. Filtering parameters is completely arbitrary, but a good rule of thumb is to identify bimodal distributions and split them modifying the available thresholds.\n",
    "In this example, with the default values we would keep a good quantity of genes while filtering potential noisy genes.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "    \n",
    "Changing the value of `min_count` will drastically change the distribution of \"Number of samples\", not change its threshold.\n",
    "In case you want to lower or increase it, you need to play with the `group`, `large_n` and `min_prop` parameters. \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "Once we are content with the threshold parameters, we can perform the actual filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c3bf6-60a5-442c-99a1-b3f0ca967a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain genes that pass the thresholds\n",
    "genes = dc.filter_by_expr(tcells, group='disease', min_count=10, min_total_count=15)\n",
    "\n",
    "# Filter by these genes\n",
    "tcells = tcells[:, genes].copy()\n",
    "tcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef676a-3c26-4b5e-b62b-47466604aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tcells.X))\n",
    "print(tcells.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6497dea-4eac-4a2a-b412-0fbf815e7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tcells.uns.items():\n",
    "    print(f\"Key: {key}, Type: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9c5b3-b16e-4bab-b5ec-ea2499e9c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle and split mixed dtype NumPy array (strings and numbers)\n",
    "def split_mixed_array(mixed_array):\n",
    "    \"\"\"Split a NumPy array with mixed types into numeric and string parts.\"\"\"\n",
    "    string_columns = mixed_array[:, [0, 3]]  # Extract the columns containing strings\n",
    "    numeric_columns = mixed_array[:, [1, 2, 4]]  # Extract the numeric columns\n",
    "    \n",
    "    # Convert numeric columns to float64 (forcing errors to NaN for robustness)\n",
    "    numeric_columns = numeric_columns.astype(np.float64)\n",
    "    \n",
    "    return string_columns, numeric_columns\n",
    "\n",
    "# Function to handle DataFrame, separating numeric and non-numeric columns\n",
    "def split_dataframe(df):\n",
    "    \"\"\"Split a DataFrame into numeric and non-numeric parts.\"\"\"\n",
    "    # Select numeric columns and convert them to float64\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).astype(np.float64)\n",
    "    \n",
    "    # Select non-numeric columns (object, category, etc.)\n",
    "    non_numeric_cols = df.select_dtypes(exclude=[np.number])\n",
    "    \n",
    "    return numeric_cols, non_numeric_cols\n",
    "\n",
    "# Function to recursively handle dictionaries, ensuring NumPy arrays are left intact\n",
    "def handle_dict(value):\n",
    "    clean_dict = {}\n",
    "    for sub_key, sub_value in value.items():\n",
    "        if isinstance(sub_value, np.ndarray):\n",
    "            print(f\"Keeping NumPy array inside dict at key '{sub_key}' as is.\")\n",
    "            clean_dict[sub_key] = sub_value  # Leave NumPy arrays unchanged\n",
    "        elif isinstance(sub_value, dict):\n",
    "            clean_dict[sub_key] = handle_dict(sub_value)  # Recursively clean sub-dictionaries\n",
    "        else:\n",
    "            clean_dict[sub_key] = sub_value  # Keep other types as is\n",
    "    return clean_dict\n",
    "\n",
    "# Create a new uns_fixed dictionary to store the fixed entries\n",
    "uns_fixed = {}\n",
    "\n",
    "# Iterate over the uns items and fix problematic types\n",
    "for key, value in tcells.uns.items():\n",
    "    # Handle NumPy arrays directly (no conversion needed for HDF5)\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"Keeping NumPy array at key '{key}' as is.\")\n",
    "        \n",
    "        if key == \"pca_anova_data\":\n",
    "            # Split mixed array into string and numeric parts\n",
    "            string_cols, numeric_cols = split_mixed_array(value)\n",
    "            print(f\"Storing separated string columns and numeric data for '{key}'\")\n",
    "            \n",
    "            # Store numeric and string data separately\n",
    "            uns_fixed[f'{key}_numeric'] = numeric_cols\n",
    "            uns_fixed[f'{key}_strings'] = string_cols\n",
    "        \n",
    "        else:\n",
    "            uns_fixed[key] = value  # No change for other NumPy arrays\n",
    "    \n",
    "    # Handle pandas DataFrame by separating numeric and non-numeric columns\n",
    "    elif isinstance(value, pd.DataFrame):\n",
    "        print(f\"Processing DataFrame at key '{key}'\")\n",
    "        \n",
    "        # Split DataFrame into numeric and non-numeric parts\n",
    "        numeric_part, non_numeric_part = split_dataframe(value)\n",
    "        \n",
    "        # Store numeric part as NumPy array\n",
    "        if not numeric_part.empty:\n",
    "            uns_fixed[f'{key}_data'] = numeric_part.values.astype(np.float64)\n",
    "        \n",
    "        # Store non-numeric part as strings (index and columns)\n",
    "        if not non_numeric_part.empty:\n",
    "            uns_fixed[f'{key}_non_numeric'] = non_numeric_part.values.astype(str)\n",
    "        \n",
    "        # Store index and columns as strings\n",
    "        uns_fixed[f'{key}_index'] = value.index.values.astype(str)\n",
    "        uns_fixed[f'{key}_columns'] = value.columns.values.astype(str)\n",
    "    \n",
    "    # Handle nested dictionaries without JSON conversion\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"Handling dict at key '{key}' without JSON serialization.\")\n",
    "        clean_dict = handle_dict(value)  # Recursively handle NumPy arrays inside the dict\n",
    "        uns_fixed[key] = clean_dict  # Keep the cleaned dict as is\n",
    "\n",
    "    # For other types (like strings, floats), keep them unchanged\n",
    "    else:\n",
    "        print(f\"Keeping key '{key}' of type '{type(value)}' unchanged.\")\n",
    "        uns_fixed[key] = value\n",
    "\n",
    "# Replace the original uns with the fixed version\n",
    "tcells.uns = uns_fixed\n",
    "\n",
    "# Now attempt to write the AnnData object to an .h5ad file\n",
    "tcells.write(\"tcells.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c756ffcd-755d-46ab-97f6-63cfc240263b",
   "metadata": {},
   "source": [
    "Another filtering strategy is to filter out genes that are not expressed in a percentage of cells and samples, as implemented\n",
    "in `decoupler.filter_by_prop`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b34858",
   "metadata": {},
   "source": [
    "## Contrast between conditions\n",
    "Once we have generated robust pseudo-bulk profiles, we can compute DEA. For this example, we will perform a simple\n",
    "experimental design where we compare the gene expression of T cells from diseased patients against controls. We will use the\n",
    "python implementation of the framework DESeq2, but we could have used any other one (`limma` or `edgeR` for example).\n",
    "For a better understanding how it works, check [DESeq2's documentation](https://pydeseq2.readthedocs.io/en/latest/). Note that\n",
    "more complex experimental designs can be used by adding more factors to the `design_factors` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1b99d-56b3-4088-9d56-92b071e01fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DESeq2\n",
    "from pydeseq2.dds import DeseqDataSet, DefaultInference\n",
    "from pydeseq2.ds import DeseqStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e71146-b441-48da-b3d2-f2252787759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DESeq2 object\n",
    "inference = DefaultInference(n_cpus=8)\n",
    "dds = DeseqDataSet(\n",
    "    adata=tcells,\n",
    "    design_factors='disease',\n",
    "    ref_level=['disease', 'normal'],\n",
    "    refit_cooks=True,\n",
    "    inference=inference,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4056b44-df95-43c6-b347-bf9fd8f5d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LFCs\n",
    "dds.deseq2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7c4a5-f386-4e9e-92ba-bcd7bfd8624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contrast between COVID-19 vs normal\n",
    "stat_res = DeseqStats(\n",
    "    dds,\n",
    "    contrast=[\"disease\", 'COVID-19', 'normal'],\n",
    "    inference=inference,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33353bda-170d-4407-ae58-5f5bf5f9ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Wald test\n",
    "stat_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c63ef9-722f-4b4c-bc9f-3d7d90402bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results\n",
    "results_df = stat_res.results_df\n",
    "results_df\n",
    "results_df.to_parquet(\"results_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d5baf-24eb-4a28-9f9d-39bd1512a0b2",
   "metadata": {},
   "source": [
    "We can plot the obtained results in a volcano plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d3d4f-9fe6-40db-8560-f13aa9fe5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_volcano_df(\n",
    "    results_df,\n",
    "    x='log2FoldChange',\n",
    "    y='padj',\n",
    "    top=20,\n",
    "    figsize=(8, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf9f18-a0e1-4e31-a146-288d07fa4dcd",
   "metadata": {},
   "source": [
    "After performing DEA, we can use the obtained gene level statistics to perform enrichment analysis. Any statistic can be used,\n",
    "but we recommend using the t-values instead of logFCs since t-values incorporate the significance of change in their value.\n",
    "We will transform the obtained t-values stored in `stats` to a wide matrix so that it can be used by `decoupler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7b1cb-6ef2-4c1e-a632-6aa4492288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = results_df[['stat']].T.rename(index={'stat': 'T cell'})\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc0996",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transcription factor activity inference\n",
    "\n",
    "The first functional analysis we can perform is to infer transcription factor (TF) activities from our transcriptomics data. We will need a gene regulatory network (GRN) and a statistical method.\n",
    "\n",
    "### CollecTRI network\n",
    "[CollecTRI](https://github.com/saezlab/CollecTRI) is a comprehensive resource\n",
    "containing a curated collection of TFs and their transcriptional targets\n",
    "compiled from 12 different resources. This collection provides an increased\n",
    "coverage of transcription factors and a superior performance in identifying\n",
    "perturbed TFs compared to our previous\n",
    "[DoRothEA](https://saezlab.github.io/dorothea/) network and other literature\n",
    "based GRNs. Similar to DoRothEA, interactions are weighted by their mode of\n",
    "regulation (activation or inhibition).\n",
    "\n",
    "For this example we will use the human version (mouse and rat are also\n",
    "available). We can use `decoupler` to retrieve it from `omnipath`. The argument\n",
    "`split_complexes` keeps complexes or splits them into subunits, by default we\n",
    "recommend to keep complexes together.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "In this tutorial we use the network CollecTRI, but we could use any other GRN coming from an inference method such as [CellOracle](https://morris-lab.github.io/CellOracle.documentation/), [pySCENIC](https://pyscenic.readthedocs.io/en/latest/) or [SCENIC+](https://scenicplus.readthedocs.io/en/latest/). \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad200c-320a-4417-8313-3d2cbfbe7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve CollecTRI gene regulatory network\n",
    "collectri = dc.get_collectri(organism='human', split_complexes=False)\n",
    "collectri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1ad1a-5cf4-4d78-994d-f1f3b424e16d",
   "metadata": {},
   "source": [
    "### Activity inference with Univariate Linear Model (ULM)\n",
    "\n",
    "To infer TF enrichment scores we will run the Univariate Linear Model (`ulm`) method. For each sample in our dataset (`mat`) and each TF in our network (`net`), it fits a linear model that predicts the observed gene expression\n",
    "based solely on the TF's TF-Gene interaction weights. Once fitted, the obtained t-value of the slope is the score. If it is positive, we interpret that the TF is active and if it is negative we interpret that it is inactive.\n",
    "\n",
    "<img src=\"../ulm.png\" />\n",
    "\n",
    "We can run `ulm` with a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b637a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer pathway activities with ulm\n",
    "tf_acts, tf_pvals = dc.run_ulm(mat=mat, net=collectri)\n",
    "tf_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3edd3b8",
   "metadata": {},
   "source": [
    "Let us plot the obtained scores for the top active/inactive transcription factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f9d96-0b3e-4e3e-9ef7-c7ca03638553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_barplot(\n",
    "    acts=tf_acts,\n",
    "    contrast='T cell',\n",
    "    top=25,\n",
    "    vertical=True,\n",
    "    figsize=(3, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf7cfe",
   "metadata": {},
   "source": [
    "In accordance to the previous pathway results, T cells seem to activate for TFs responsible for cell growth (E2F4, TFDP1, E2F1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3243b4",
   "metadata": {},
   "source": [
    "Like with pathways, we can explore how the target genes look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c27d9b-e0e8-41db-92a4-a5e0a28fc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract logFCs and pvals\n",
    "logFCs = results_df[['log2FoldChange']].T.rename(index={'log2FoldChange': 'T cell'})\n",
    "pvals = results_df[['padj']].T.rename(index={'padj': 'T cell'})\n",
    "\n",
    "# Plot\n",
    "dc.plot_volcano(\n",
    "    logFCs=logFCs,\n",
    "    pvals=pvals,\n",
    "    contrast='T cell',\n",
    "    name='E2F4',\n",
    "    net=collectri,\n",
    "    top=10,\n",
    "    sign_thr=0.05,\n",
    "    lFCs_thr=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd6ccef-879b-4970-ba96-71bfe0e853f5",
   "metadata": {},
   "source": [
    "We can also plot the network of interesting TFs (top and bottom by activity) and color the nodes by activity and target gene expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd5d00-453b-4702-9538-ab8616a7121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_network(\n",
    "    net=collectri,\n",
    "    obs=mat,\n",
    "    act=tf_acts,\n",
    "    n_sources=['MYC', 'E2F4', 'HSF1', 'GATA6'],\n",
    "    n_targets=15,\n",
    "    node_size=100,\n",
    "    figsize=(7, 7),\n",
    "    c_pos_w='darkgreen',\n",
    "    c_neg_w='darkred',\n",
    "    vcenter=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b9eaf-14e8-4902-9f53-7f9740d4d036",
   "metadata": {},
   "source": [
    "Green edges are positive regulation (activation), red edges are negative regulation (inactivation):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325fc36f",
   "metadata": {},
   "source": [
    "## Pathway activity inference\n",
    "\n",
    "Another analysis we can perform is to infer pathway activities from our transcriptomics data.\n",
    "\n",
    "### PROGENy model\n",
    "\n",
    "[PROGENy](https://saezlab.github.io/progeny/) is a comprehensive resource containing a curated collection of pathways and their target genes, with weights for each interaction.\n",
    "For this example we will use the human weights (other organisms are available) and we will use the top 500 responsive genes ranked by p-value. Here is a brief description of each pathway:\n",
    "\n",
    "- **Androgen**: involved in the growth and development of the male reproductive organs.\n",
    "- **EGFR**: regulates growth, survival, migration, apoptosis, proliferation, and differentiation in mammalian cells\n",
    "- **Estrogen**: promotes the growth and development of the female reproductive organs.\n",
    "- **Hypoxia**: promotes angiogenesis and metabolic reprogramming when O2 levels are low.\n",
    "- **JAK-STAT**: involved in immunity, cell division, cell death, and tumor formation.\n",
    "- **MAPK**: integrates external signals and promotes cell growth and proliferation.\n",
    "- **NFkB**: regulates immune response, cytokine production and cell survival.\n",
    "- **p53**: regulates cell cycle, apoptosis, DNA repair and tumor suppression.\n",
    "- **PI3K**: promotes growth and proliferation.\n",
    "- **TGFb**: involved in development, homeostasis, and repair of most tissues.\n",
    "- **TNFa**: mediates haematopoiesis, immune surveillance, tumour regression and protection from infection.\n",
    "- **Trail**: induces apoptosis.\n",
    "- **VEGF**: mediates angiogenesis, vascular permeability, and cell migration.\n",
    "- **WNT**: regulates organ morphogenesis during development and tissue repair.\n",
    "\n",
    "To access it we can use `decoupler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9598d-d980-4f83-a018-c0e783babe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve PROGENy model weights\n",
    "progeny = dc.get_progeny(top=500)\n",
    "progeny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799e15d-4656-474c-bf71-9a04a47c3db6",
   "metadata": {},
   "source": [
    "### Activity inference with Multivariate Linear Model (MLM)\n",
    "\n",
    "To infer pathway enrichment scores we will run the Multivariate Linear Model (`mlm`) method. For each sample in our dataset (`adata`), it fits a linear model that predicts the observed gene expression based on all pathways' Pathway-Gene interactions weights.\n",
    "Once fitted, the obtained t-values of the slopes are the scores. If it is positive, we interpret that the pathway is active and if it is negative we interpret that it is inactive.\n",
    "\n",
    "<img src=\"../mlm.png\" />\n",
    "     \n",
    "We can run `mlm` with a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ba03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer pathway activities with mlm\n",
    "pathway_acts, pathway_pvals = dc.run_mlm(mat=mat, net=progeny)\n",
    "pathway_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4bd5d",
   "metadata": {},
   "source": [
    "Let us plot the obtained scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb82b3-e30d-4438-8910-763ec27a14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_barplot(\n",
    "    acts=pathway_acts,\n",
    "    contrast='T cell',\n",
    "    top=25,\n",
    "    vertical=False,\n",
    "    figsize=(6, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0b5a9",
   "metadata": {},
   "source": [
    "It looks like JAK-STAT, a known immunity pathway is more active in T cells from COVID-19 patients than in controls. To further explore how the target genes of a pathway of interest behave, we can plot them in scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8b9ea-c7ef-494b-bd52-17a1aac5be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_targets(\n",
    "    data=results_df,\n",
    "    stat='stat',\n",
    "    source_name='JAK-STAT',\n",
    "    net=progeny,\n",
    "    top=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2933a7-97b6-457f-891d-6ac6bb0dbe9b",
   "metadata": {},
   "source": [
    "The observed activation of JAK-STAT is due to the fact that majority of its target genes with positive weights have positive\n",
    "t-values (1st quadrant), and the majority of the ones with negative weights have negative t-values (3d quadrant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc171c8",
   "metadata": {},
   "source": [
    "## Functional enrichment of biological terms\n",
    "\n",
    "Finally, we can also infer activities for general biological terms or processes.\n",
    "\n",
    "### MSigDB gene sets\n",
    "\n",
    "The Molecular Signatures Database ([MSigDB](http://www.gsea-msigdb.org/gsea/msigdb/)) is a resource containing a collection of gene sets annotated to different biological processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e11ac-af86-400c-9e6a-c409548e25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve MSigDB resource\n",
    "msigdb = dc.get_resource('MSigDB')\n",
    "msigdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd7f04-8363-4683-9309-622bf405feb7",
   "metadata": {},
   "source": [
    "As an example, we will use the hallmark gene sets, but we could have used any other. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "    \n",
    "To see what other collections are available in MSigDB, type: `msigdb['collection'].unique()`.\n",
    "\n",
    "</div>  \n",
    "\n",
    "We can filter by for `hallmark`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892b3b0-f251-4604-be01-8ae0d27b87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by hallmark\n",
    "msigdb = msigdb[msigdb['collection']=='hallmark']\n",
    "\n",
    "# Remove duplicated entries\n",
    "msigdb = msigdb[~msigdb.duplicated(['geneset', 'genesymbol'])]\n",
    "\n",
    "# Rename\n",
    "msigdb.loc[:, 'geneset'] = [name.split('HALLMARK_')[1] for name in msigdb['geneset']]\n",
    "\n",
    "msigdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f84244-124f-464c-a13a-3e9349173d9d",
   "metadata": {},
   "source": [
    "### Enrichment with Over Representation Analysis (ORA)\n",
    "\n",
    "To infer functional enrichment scores we will run the Over Representation Analysis (`ora`) method.\n",
    "As input data it accepts an expression matrix (`decoupler.run_ora`) or the results of differential expression analysis (`decoupler.run_ora_df`).\n",
    "For the former, by default the top 5% of expressed genes by sample are selected as the set of interest (S*), and for the latter a user-defined\n",
    "significance filtering can be used.\n",
    "Once we have S*, it builds a contingency table using set operations for each set stored in the gene set resource being used (`net`).\n",
    "Using the contingency table, `ora` performs a one-sided Fisher exact test to test for significance of overlap between sets.\n",
    "The final score is obtained by log-transforming the obtained p-values, meaning that higher values are more significant.\n",
    "\n",
    "<img src=\"../ora.png\" />\n",
    "     \n",
    "We can run `ora` with a simple one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer enrichment with ora using significant deg\n",
    "top_genes = results_df[results_df['padj'] < 0.05]\n",
    "\n",
    "# Run ora\n",
    "enr_pvals = dc.get_ora_df(\n",
    "    df=top_genes,\n",
    "    net=msigdb,\n",
    "    source='geneset',\n",
    "    target='genesymbol'\n",
    ")\n",
    "\n",
    "enr_pvals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3053c",
   "metadata": {},
   "source": [
    "Then we can visualize the most enriched terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89436383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.plot_dotplot(\n",
    "    enr_pvals.sort_values('Combined score', ascending=False).head(15),\n",
    "    x='Combined score',\n",
    "    y='Term',\n",
    "    s='Odds ratio',\n",
    "    c='FDR p-value',\n",
    "    scale=0.5,\n",
    "    figsize=(3, 9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f9835-ec97-471c-90e3-6b0e7b9d360e",
   "metadata": {},
   "source": [
    "We can also plot the running score for a given gene set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94982f2c-2256-47a2-86ce-35184c3ecf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "dc.plot_running_score(\n",
    "    df=results_df,\n",
    "    stat='stat',\n",
    "    net=msigdb,\n",
    "    source='geneset',\n",
    "    target='genesymbol',\n",
    "    set_name='MYC_TARGETS_V1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a816ea-0c07-479f-a51b-98f44d5318a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
